function net = initializeRegNetwork(opts)
scal = 0.01 ;
init_bias = 0.1;
net.layers = {} ;

% Block 1
net.layers{end+1} = struct('type', 'conv', ...
    'filters', scal * randn(5,5, opts.inNode, 32, 'single'), ...
    'biases', init_bias*ones(1, 32, 'single'), ...
    'stride', 1, ... %1
    'pad', 0, ...
    'learningRate', [1 2], ...
    'weightDecay', [1 0]);
net.layers{end+1} = struct('type', 'relu') ;
net.layers{end+1} = struct('type', 'pool', ...
    'method', 'max', ...
    'pool', [3 3], ...
    'stride', 2, ...
    'pad', 0) ;
net.layers{end+1} = struct('type', 'normalize', ...
    'param', [5 1 0.0001/5 0.75]) ;


% Block 2
net.layers{end+1} = struct('type', 'conv', ...
    'filters', scal * randn(3,3, 32, 32, 'single'), ...
    'biases', init_bias*ones(1, 32, 'single'), ...
    'stride', 1, ... %1
    'pad', 0, ...
    'learningRate', [1 2], ...
    'weightDecay', [1 0]);
net.layers{end+1} = struct('type', 'relu') ;
net.layers{end+1} = struct('type', 'pool', ...
    'method', 'max', ...
    'pool', [3 3], ...
    'stride', 2, ...
    'pad', 0) ;
net.layers{end+1} = struct('type', 'normalize', ...
    'param', [5 1 0.0001/5 0.75]) ;

% Block 3
net.layers{end+1} = struct('type', 'conv', ...
    'filters', scal * randn(3,3, 32, 64, 'single'), ...
    'biases', init_bias*ones(1, 64, 'single'), ...
    'stride', 1, ... %1
    'pad', 1, ...
    'learningRate', [1 2], ...
    'weightDecay', [1 0]);
net.layers{end+1} = struct('type', 'relu') ;

% Block 4
net.layers{end+1} = struct('type', 'conv', ...
    'filters', scal * randn(3,3, 64, 64, 'single'), ...
    'biases', init_bias*ones(1, 64, 'single'), ...
    'stride', 1, ... %1
    'pad', 0, ...
    'learningRate', [1 2], ...
    'weightDecay', [1 0]);
net.layers{end+1} = struct('type', 'relu') ;
net.layers{end+1} = struct('type', 'pool', ...
    'method', 'max', ...
    'pool', [3 3], ...
    'stride', 2, ...
    'pad', 0) ;
net.layers{end+1} = struct('type', 'normalize', ...
    'param', [5 1 0.0001/5 0.75]) ;
net.layers{end+1} = struct('type', 'dropout', ...
    'rate', 0.5) ;

% Block 5
net.layers{end+1} = struct('type', 'conv', ...
    'filters', scal * randn(12,7, 64, 1024, 'single'), ...
    'biases', init_bias*ones(1, 1024, 'single'), ...
    'stride', 1, ... %1
    'pad', 0, ...
    'learningRate', [1 2], ...
    'weightDecay', [1 0]);
net.layers{end+1} = struct('type', 'relu') ;
net.layers{end+1} = struct('type', 'normalize', ...
    'param', [5 1 0.0001/5 0.75]) ;

% Block 6
net.layers{end+1} = struct('type', 'conv', ...
    'weights', {{scal*randn(1,1,1024,2048, 'single'), init_bias*ones(1, 2048, 'single')}}, ...
    'stride', 1, ...
    'pad', 0, ...
    'filtersLearningRate', 1, ...
    'biasesLearningRate', 2, ...
    'filtersWeightDecay', 1, ...
    'biasesWeightDecay', 0) ;
net.layers{end+1} = struct('type', 'relu') ;
net.layers{end+1} = struct('type', 'dropout', ...
    'rate', 0.5) ;

net.layers{end+1} = struct('type', 'conv', ...
    'weights', {{scal*randn(1,1,2048,1024, 'single'), init_bias*ones(1, 1024, 'single')}}, ...
    'stride', 1, ...
    'pad', 0, ...
    'filtersLearningRate', 1, ...
    'biasesLearningRate', 2, ...
    'filtersWeightDecay', 1, ...
    'biasesWeightDecay', 0) ;
net.layers{end+1} = struct('type', 'relu') ;

%Block 7
net.layers{end+1} = struct('type', 'conv', ...
    'weights', {{scal*randn(1,1,1024,opts.outNode, 'single'), init_bias*ones(1, opts.outNode, 'single')}}, ...
    'stride', 1, ...
    'pad', 0, ...
    'filtersLearningRate', 1, ...
    'biasesLearningRate', 2, ...
    'filtersWeightDecay', 1, ...
    'biasesWeightDecay', 0) ;

% Block 8
net.layers{end+1} = struct('type', opts.lossFunc) ;

%dagNN format
net = fromSimpleNN_custom(net, 'canonicalNames', true);

%rename the last layer to "objective"
net.renameLayer(net.layers(end).name,net.layers(end).outputs{1});

net.addLayer('error', dagnn.RegLoss('loss', 'mpe'), ...
    {'prediction','label'}, 'error') ;